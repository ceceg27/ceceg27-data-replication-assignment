---
title: "AN588 Final Replication Analysis"
author: "Cecelia Gerstenbacher"
date: "12/10/2021"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    theme: yeti 
---

# Decreasing seagrass density negatively influences associated fauna (McCloskey and Unsworth, 2015)
```{r, echo=FALSE, out.width = '70%'}
knitr::include_graphics("img/seagrass.jpg", error = FALSE)
```



<https://peerj.com/articles/1053/>

Required packages:

```{r, message = FALSE}
library(curl)
library(ggplot2)
library(forcats)
library(vegan)
```

## Study Description

Seagrasses are marine angiosperms which exist on all continents except Antarctica and often form dense monoculture meadows in shallow and calm coastal inlets. These dense meadows provide, among other things, habitat to a wide variety of marine organisms, many of which are endangered or commercially valuable. Unfortunately, seagrasses are experiencing rapid degradation, as anthropogenic threats such as trawling, dredging, and eutrophication have caused a tenfold decrease in seagrass cover over the last 40 years.

Locally, this degradation can look like a boat anchor dragging through a meadow, ripping up seagrass and reducing the plant, or "shoot" density in the vicinity. This subsequently reduces the complexity of the habitat. Because complex habitats provide more hide space for juveniles and vulnerable prey, a reduction in this complexity is theorized to reduce the density and diversity of ecosystem associated fauna, even on small scales. To test the hypothesis that a local decrease in seagrass density will negatively impact associatef fauna, this study collected motile fauna samples using seine net hauls from six 6x6 meter seagrass plots from the same meadow over a gradient of varying habitat characteristics, including seagrass percent cover and shoot density. They recorded each animal in each siene net haul. They then repeated this for ten 6x6 seagrass plots at the same location the subsequent year.

In order to statistically confirm if there is a difference in faunal density and diversity between high and low cover plots the following analyses were employed

##### - Summary stats (means, standard deviations)
##### - ANOSIM (analysis of similarity)
##### - Shannon Wiener Diversity Index
##### - Non-metric Multidimensional scaling (nMDS) with superimposed Bray Curtis Clusters
##### - Percentage Similarity Contributions (SIMPER)
##### - Spearmans Rank Correlations
##### - T test and Mann Whitney U test 

For the purposes of this assignment, we will be replicating the Shannon Wiener Diversity Index as well as several T test and Mann Whitney U tests. Further, we will replicate all summary statistics, and create a figure showing the mean fish abundance per seine haul for 8 high and 8 low cover plots, including standard deviation.

**NOTE** I did attempt to conduct some of the other analyses. Unfortunately they require information on seagrass percent cover which is not provided in the raw data. There is a table showing percent covers for six of the plots in the beginning of the results, but there were 16 plots total, and there is no way to tell which percent cover corresponds to which plot. This made any analysis using percent cover instead of "high" and "low" catagories impossible. Luckily there was enough I could do without this info, but it did hinder me. I didn't realize this until I was deep into the analyses, and I decided to just work with what I had. 

## Getting Started

### Loading data and collecting summary stats

First, lets load and explore the data.

```{r}
library(curl)
f<- curl ("https://raw.githubusercontent.com/ceceg27/ceceg27-data-replication-assignment/main/meansandsd.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
summary(d)
```

This data is not an exact replica of the format in which the raw data was originally provided. I have went ahead and changed the format to make it conducive to replication in R, since the analysis was not originally done in R. This new format allows us to get the means and standard deviations for each species, and for each genre of plot (low or high percent cover). The original raw data is in the repo under the name "rawdata.csv"

### Collecting means and standard deviations 
Above, the summary function provides us with each mean, but we want each mean to be saved as a variable, as well as each sd. Lets do that below.

```{r}
m1 <- mean(d$Pomatoschistus.minutus.low)
m1
sd1 <- sd(d$Pomatoschistus.minutus.low)
sd1
#this works well, time to do it with the rest of the data
m2 <- mean(d$Pomatoschistus.minutus.high)
sd2 <- sd (d$Pomatoschistus.minutus.high)
m3 <- mean(d$Symphodus.melops.high)
sd3 <- sd(d$Symphodus.melops.high)
m4 <- mean (d$Symphodus.melops.low)
sd4 <- sd(d$Symphodus.melops.low)
m5 <- mean(d$Spinachia.spinachia.high)
sd5 <- sd(d$Spinachia.spinachia.high)
m6 <- mean (d$Spinachia.spinachia.low)
sd6 <- sd(d$Spinachia.spinachia.low)
m7 <- mean(d$Pleuronectes.platessa.high)
sd7 <- sd(d$Pleuronectes.platessa.high)
m8 <- mean(d$Pleuronectes.platessa.low)
sd8 <- sd(d$Pleuronectes.platessa.low)
m9 <- mean(d$Palaemon.serratus.high)
sd9 <- sd(d$Palaemon.serratus.high)
m10 <- mean(d$Palaemon.serratus.low)
sd10 <- sd(d$Palaemon.serratus.low)
m11 <- mean (d$Crangon.crangon.high)
sd11 <- sd(d$Crangon.crangon.high)
m12 <- mean(d$Crangon.crangon.low)
sd12 <- sd(d$Crangon.crangon.low)
m13 <- mean(d$Taurulus.bubalis.high)
sd13 <-sd(d$Taurulus.bubalis.high)
m14 <- mean(d$Taurulus.bubalis.low)
sd14 <- sd(d$Taurulus.bubalis.low)
m15 <- mean(d$Callionymus.lyra.high)
sd15 <- sd(d$Callionymus.lyra.high)
m16 <- mean(d$Callionymus.lyra.low)
sd16 <- sd(d$Callionymus.lyra.low)
m17 <- mean(d$Gobiusculus.flavescens.high)
sd17 <- sd(d$Gobiusculus.flavescens.high)
m18 <- mean(d$Gobiusculus.flavescens.low)
sd18 <- sd(d$Gobiusculus.flavescens.low)
m19 <- mean(d$Clupea.harengus.high)
sd19 <- sd(d$Clupea.harengus.high)
m20 <- mean(d$Clupea.harengus.low)
sd20 <- sd(d$Clupea.harengus.low)
m21 <- mean(d$Centrolabrus.exoletus.high.)
sd21 <- sd(d$Centrolabrus.exoletus.high.)
m22 <- mean(d$Centrolabrus.exoletus.low.)
sd22 <- sd(d$Centrolabrus.exoletus.low.)
m23 <- mean(d$Labrus.bergylta.high)
sd23 <- sd(d$Labrus.bergylta.high)
m24 <- mean(d$Labrus.bergylta.low)
sd24 <- sd(d$Labrus.bergylta.low)
m25 <- mean(d$Pollachius.pollachius.high)
sd25 <- sd(d$Pollachius.pollachius.high)
m26 <- mean(d$Pollachius.pollachius.low)
sd26 <- sd(d$Pollachius.pollachius.low)
m27 <- mean(d$Atherina.prebyter.high)
sd27 <- sd(d$Atherina.prebyter.high)
m28 <- mean(d$Atherina.prebyter.low)
sd28 <- sd(d$Atherina.prebyter.low)
m29 <- mean(d$Syngnathus.acus.high)
sd29 <- sd(d$Syngnathus.acus.high)
m30 <- mean(d$Syngnathus.acus.low)
sd30 <- sd(d$Syngnathus.acus.low)
m31 <- mean(d$Ciliata.mustela.high)
sd31 <- sd(d$Ciliata.mustela.high)
m32 <- mean(d$Ciliata.mustela.low)
sd32 <- sd(d$Ciliata.mustela.low)
m33 <- mean(d$Gadus.morhua.high)
sd33 <- sd(d$Gadus.morhua.high)
m34 <- mean(d$Gadus.morhua.low)
sd34 <- sd(d$Gadus.morhua.low)
m35 <- mean(d$Scyliorhinus.canicula.high)
sd35 <- sd(d$Scyliorhinus.canicula.high)
m36 <- mean(d$Scyliorhinus.canicula.low)
sd36 <- sd(d$Scyliorhinus.canicula.low)
m37 <- mean(d$Entelurus.aequoreus.high)
sd37 <- sd(d$Entelurus.aequoreus.high)
m38 <- mean(d$Entelurus.aequoreus.low)
sd38 <- sd(d$Entelurus.aequoreus.low)
```

Ok that was painful and I'm sure there was a better way to do it but hey. Now I will take all of these values and make them into two vectors so we don't have dozens of means and sds floating around. 

```{r}
means <- c(m1, m2, m3, m4, m5, m6, m7, m8, m9, m10, m11, m12, m13, m14, m15, m16, m17, m18, m19, m20, m21, m22, m23, m24, m25, m26, m27, m28, m29, m30, m31, m32, m33, m34, m35, m36, m37, m38)
means
sds <- c(sd1, sd2, sd3, sd4, sd5, sd6, sd7, sd8, sd9, sd10, sd11, sd12, sd13, sd14, sd15, sd16, sd17, sd18, sd19, sd20, sd21, sd22, sd23, sd24, sd25, sd26, sd27, sd28, sd29, sd30, sd31, sd32, sd33, sd34, sd35, sd36, sd37, sd38)
sds
```

Nice, now we have means and sds which we can actually work with, and which match the means and sds in the data that the paper provided.

## Replicating the Figure

I will be replicating a bargraph figure which shows the means and standard deviations for the high and low cover plots for each species collected during the siene net hauls. 

After lots of trials, I couldn't figure out how to get the means and sds within the vectors I created to segregate based on both species and percent cover in a ggplot. I think it would be much easier to just have these values in a csv, but I did want to show that I am capable of calculating them in R. This is what the authors did (they calculated mean and sd in excel before exporting the data for analysis). Sooooo, now that I've shown that I can get mean and sd in R, I'm going to create and import a new dataset, so I can properly segregate in my ggplot. These mean and ad vectors will become useful later anyway.

```{r}
library(curl)
f<- curl ("https://raw.githubusercontent.com/ceceg27/ceceg27-data-replication-assignment/main/ggplotdata.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
summary(d)
head(d)
```

Ok now we can make the ggplot much easier.

```{r}
p <-ggplot(d, aes(x=species, y=sqrt(mean), fill=percent.cover)) + 
    geom_bar(position=position_dodge(),stat="identity", color = "black", width = .6) + #formatting bars
    geom_errorbar(aes(x = species, ymin=sqrt(mean), ymax=sqrt(mean + sd)),
                  width=.4,                    
                  position=position_dodge(width = .6))  # making the error bars
p <- p + scale_fill_manual(labels = c("High % Cover", "Low % Cover"), values = c(rep(c("black", "gray75"))))#adding color
p <- p + theme(legend.box.background = element_rect(color = "black",fill = "white"),legend.title=element_blank(), legend.position = c(.9,.8)) #making legend look like original
p <- p + theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()) #removing grid and gray background
p <- p + scale_y_continuous(expand = c(0.0,0.0),
                   limits = c(0.0,7)) #making graph start at 0
p <- p + theme(axis.text.x = element_text(angle = 65, vjust = 1, hjust=1)) + coord_equal(1/0.6) #adjusting x axis
library(forcats)
p <- p + aes(x = fct_inorder(species)) #reordering to match the source
p <- p + ylab("Faunal bundance (log) per siene haul") +xlab("") #label 

p
```


Now lets compare it to the original: 

```{r, echo=FALSE, out.width = '70%'}
knitr::include_graphics("img/replicated.figure.png", error = FALSE)
```


At this point, the bargraph is looking about 95% similar to the original, but I am still facing one problem. 

The original bar graph says that the data was log transformed, however if I try to log transform this data it gives me negative numbers and completely messes up the graph. When I don't transform the data, it gives me the same plot but to a different scale, with the y axis going up to 30. In the original plot the y axis goes up to 7. I began to think maybe they had done some other transformation on the data. I square rooted the means and sds and it gave me something very similar to the original graph. The means are now the same, but the sds look a little bit off. It would have been very beneficial if they reported exactly how they transformed the data to get it to scale. 

Despite that, I'm pretty happy with how the graph turned out. It actually took forever to make what I originally thought would be a simple graph, but I did it. 

Before we move on, I can't stand that the bargraph is in black and white, so I decided to change its coloring. 

```{r, echo = FALSE}
p <-ggplot(d, aes(x=species, y=sqrt(mean), fill=percent.cover)) + 
    geom_bar(position=position_dodge(),stat="identity", color = "black", width = .6) + #formatting bars
    geom_errorbar(aes(x = species, ymin=sqrt(mean), ymax=sqrt(mean + sd)),
                  width=.4,                    
                  position=position_dodge(width = .6))  # making the error bars
p <- p + scale_fill_manual(labels = c("High % Cover", "Low % Cover"), values = c(rep(c("lightblue", "pink"))))#adding color
p <- p + theme(legend.box.background = element_rect(color = "black",fill = "white"),legend.title=element_blank(), legend.position = c(.9,.8)) #making legend look like original
p <- p + theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()) #removing grid and gray background
p <- p + scale_y_continuous(expand = c(0.0,0.0),
                   limits = c(0.0,7)) #making graph start at 0
p <- p + theme(axis.text.x = element_text(angle = 65, vjust = 1, hjust=1)) + coord_equal(1/0.6) #adjusting x axis
library(forcats)
p <- p + aes(x = fct_inorder(species)) #reordering to match the source
p <- p + ylab("Faunal bundance (log) per siene haul") +xlab("") #label 

p
```

Now lets get on to some more complex data analysis.

## Species Variability between high and low plots

Now that this figure is created, I think it will be valuable to explore some of the variation we see within species among high and low percent cover plots. Within the original text, this is done via t tests and Mann Whitney tests. 

### Common Prawn 

```{r, echo=FALSE, out.width = '60%'}
knitr::include_graphics("img/commonprawn.jpg", error = FALSE)
```

Lets First look at the difference in common prawn (Palaemon serratus) between high and low plots. Because this is a small amount of data, I will just be putting them into vectors

```{r}
prawn_high <- c(51, 45, 2, 3, 3, 22, 77, 15)
prawn_low <- c(20, 68, 10, 107, 92, 53, 12, 35)

t.test <- t.test(prawn_high, prawn_low)
t.test
```
Here, we are given a p value of 0.1928. Interestingly, within the text this value is 0.1628. I am not sure if this is a mistype on their part, or if somehow the data is slightly different. One key thing to point out is that this test is done on sampmles from 2013. In their raw data, they do not specify which year the data came from. I can only assume that is it 2013, but it may be 2012. The authors should specify this. However, in both mine and the original test, there is no significant difference between common prawn numbers between high and low plots. 

### Plaice 

```{r, echo=FALSE, out.width = '60%'}
knitr::include_graphics("img/plaice.jpg", error = FALSE)
```

Next lets check the Plaices (Pleuronectes platessa). A Mann Whitney test, also known as the Wilcox test, is used here as the data is non parametric 

```{r}
Plaicehigh <- c(0, 0, 0, 0, 0, 0, 1, 0)
Plaicelow <- c(2, 7, 2, 0, 1, 3, 1, 2)
wilcox.test(Plaicehigh, Plaicelow)
```
Here we are given a p value of .00332. This corresponds with the result in the text of p < .005. There is no record of the exact p value in the text. What the authors fail to emphasize is that the low cover plots actually had more wrasses than the high cover plots, which does not support their original hypothesis. 

## Shannon Wiener Diversity Index

The Shannon Wiener Diversity Index is a metric used to determine diversity when a system contains too many species to be individually accounted for. It uses a small sample to extrapolate overall system diversity. The higher the index value, the more diverse the system is predicted to be. 

For the Shannon Diversity Index, we want to run two separate analyses, one on the high density plots and one on the low density plots. As our data currently stands, the diversity command will only run this analysis on all the data combined. I thus think is necessary to separate the data into two sheets. 

### High diversity calculation
```{r}
library(curl)
f<- curl ("https://raw.githubusercontent.com/ceceg27/ceceg27-data-replication-assignment/main/shannonhigh.csv")
sh <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
summary(sh)
head(sh)
```

```{r}
shannonh <- diversity(sh, index = "shannon")
shannonh
```

### Low diversity calculation
```{r}
library(curl)
f<- curl ("https://raw.githubusercontent.com/ceceg27/ceceg27-data-replication-assignment/main/shannonlow.csv")
sl <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
summary(sl)
head(sl)
```

```{r}
shannonl <- diversity(sl, index = "shannon")
shannonl
```

### Comparing to original 

That wasn't so bad! While there is no table in the text which shows the individual results of the Shannon Wiener Diversity Index, there is luckily a table in the raw data. Lets make our results into a similar table, and compare. 

```{r}
shannon_table <- data.frame(setNames(shannonl, shannonh))
shannon_table
```

```{r, echo=FALSE, out.width = '60%'}
knitr::include_graphics("img/diversitytable.png", error = FALSE)
```

As you can see, our results and the results from the original raw data are identical! Now all we have left to do is collect and average and standard deviations from our data, which I will do below. 

```{r}
shmean <- mean(shannonh)
shsd <- sd(shannonh)
slmean <- mean(shannonl)
slsd <- sd(shannonl)

shmean
shsd
slmean
slsd
```

The means and standard deviations are also identical to the original data! These means and sds are reported both in the original raw data table above, and in the final text. They are also determined to be statistically different using a t test. Let's see if our data is statistically different at p < .05. 

```{r}
t.test <- t.test(shannonh, shannonl, data = shannon_table)
t.test
```

Our results shows that Shannon Wiener diversity is significantly higher in the high cover samples than in the low cover samples with a p value of .038 (t test, p<.05). This supports the original paper's findings. 

## Conclusion

Overall I was able to produce exact replicates of the Shannon Diversity Index, T tests, Mann Whitney tests, means, standard deviations, and the figure showing the means and standard deviations for each species within in high and low plots. I struggled most with formatting my data properly in excel to be imported into R. The authors didn't leave the data in a nice format for R to understand. I also struggled with the lack of data and organization, as this limited what analyses I was able to conduct. This experience was telling of how even articles which provide raw data aren't exactly easy to replicate. 







